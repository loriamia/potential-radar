# main.py é¡¹ç›®ä¸»å…¥å£
import json
import csv
import os
from github_api import get_github_trending_repos,get_github_repos
from opendigger_analysis import batch_analysis_repos
from config import RESULT_SAVE_PATH, GITHUB_URLS
from correlation_analysis import analyze_correlations
from PCA import pca_with_metric_weight

def save_result_to_json(result: list, save_path: str):
    """å°†ç»“æœä¿å­˜åˆ°æœ¬åœ°jsonæ–‡ä»¶"""
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=4)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶: {save_path}")

def output_to_csv(result: dict, correlations: dict, filename: str):
    """å°†resultå’Œcorrelationsè¾“å‡ºä¸ºCSVè¡¨æ ¼ï¼Œæ¯ä¸€ä¸ªæ•°ç»„ä¸ºä¸€è¡Œ"""
    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        # å†™å…¥ result æ•°æ®
        for metric, values in result.items():
            writer.writerow([metric] + values)
        # ç©ºè¡Œåˆ†éš”
        writer.writerow([])
        # å†™å…¥ correlations æ•°æ®
        for metric, corr in correlations.items():
            writer.writerow([f"correlation_{metric}", corr])
    print(f"\nâœ… ç»“æœå’Œç›¸å…³æ€§å·²ä¿å­˜åˆ°CSVæ–‡ä»¶: {filename}")

if __name__ == "__main__":
    metrics = ["inactive_contributors","contributors", "participants", "bus_factor","issue_resolution_duration", "change_request_resolution_duration", "activity", "issue_response_time", 
               "change_request_response_time", "openrank"]  # ç¤ºä¾‹æŒ‡æ ‡æ•°ç»„

    # print("=" * 50)
    # print("å¼€å§‹çˆ¬å–GitHubä»“åº“å¹¶åˆ†æ...")
    # print("=" * 50)

    # 1. çˆ¬å–ä»“åº“åœ°å€
    # repo_list = get_github_trending_repos()
    # repo_list = get_github_repos(200)
    # if not repo_list:
    #     print("âŒ æœªçˆ¬å–åˆ°ä»»ä½•ä»“åº“åœ°å€ï¼Œç¨‹åºç»ˆæ­¢")
    #     exit()

    # ä½¿ç”¨ä¿å­˜çš„repoâ€”â€”list.jsonï¼Œæ–¹ä¾¿å¤ç°
    repo_list = json.load(open("repos_snapshot.json"))

    # 2. æ‰¹é‡åˆ†æä»“åº“ï¼Œå¾—åˆ°å¹³å‡activityå€¼çš„æ•°ç»„ã€æ ¸å¿ƒç»“æœã€‘
    result_file = "result.json"
    if os.path.exists(result_file):
        print(f"ä»æ–‡ä»¶ {result_file} åŠ è½½resultï¼Œé¿å…é‡å¤è®¡ç®—...")
        with open(result_file, "r", encoding="utf-8") as f:
            result = json.load(f)
    else:
        print("è®¡ç®—result...")
        result = batch_analysis_repos(repo_list, metrics)
        save_result_to_json(result, result_file)

    # contributors:contributors/participants
    if "contributors" in result and "participants" in result:
        inactive = result["contributors"]
        contrib = result["participants"]
        metrics.insert(len(metrics) - 1, "contributors_per_participant")
        if len(inactive) == len(contrib):
            result["contributors_per_participant"] = [inactive[i] / contrib[i] if contrib[i] != 0 else 0 for i in range(len(inactive))]

    # 3. æ‰“å°æœ€ç»ˆç»“æœæ•°ç»„
    print("\n" + "=" * 50)
    3
    # print("ğŸ“ˆ æœ€ç»ˆç»“æœæ•°ç»„ (ä»“åº“+è¿‘3ä¸ªæœˆå¹³å‡activityå€¼):")
    # print("=" * 50)
    # print(result)



    # åœ¨è·å– result å
    correlations = analyze_correlations(metrics, result)
    print("ç›¸å…³æ€§åˆ†æç»“æœ:", correlations)
    
    # å»æ‰resultçš„æœ€åä¸€è¡Œï¼ˆæœ€åä¸€ä¸ªæ ·æœ¬ï¼‰å’Œmetricsçš„æœ€åä¸€ä¸ªæŒ‡æ ‡
    result_trimmed = {k: v[:-1] for k, v in result.items()}
    metrics_trimmed = metrics[:-1]
    
    # å†å»æ‰"contributors"å’Œ"participants"
    result_trimmed = {k: v for k, v in result_trimmed.items() if k not in ["contributors", "participants", "openrank"]}
    metrics_trimmed = [m for m in metrics_trimmed if m not in ["contributors", "participants", "openrank"]]
    
    (pca_loadings_df, component_var_ratio, raw_metric_weights,
     pca_composite_scores, standardized_df) = pca_with_metric_weight(result_trimmed, metrics_trimmed)
    print("3. åŸå§‹æŒ‡æ ‡çš„ç»¼åˆæƒé‡ï¼ˆä¸»æˆåˆ†æƒé‡è¿˜åŸåï¼Œæƒé‡å’Œä¸º1ï¼‰ï¼š")
    for metric, weight in sorted(raw_metric_weights.items(), key=lambda x: x[1], reverse=True):
        print(f"   {metric:<35}: {weight:.6f}")

    print("=" * 80)
    # 4. è¾“å‡ºä¸ºCSVè¡¨æ ¼
    # output_to_csv(result, correlations, "result.csv")
    # 4. å¯é€‰ï¼šä¿å­˜ç»“æœåˆ°æœ¬åœ°
    #save_result_to_json(activity_array, RESULT_SAVE_PATH)

    # å•ç‹¬æå–çº¯activityå€¼çš„æ•°ç»„ï¼ˆæŒ‰éœ€ï¼‰
    # only_activity_values = [item["avg_activity_3months"] for item in activity_array]
    # print("\nâœ¨ çº¯å¹³å‡æ´»è·ƒåº¦æ•°å€¼æ•°ç»„: ", only_activity_values)